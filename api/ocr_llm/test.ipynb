{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cc0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78.1\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb213e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'from_json' from 'jiter' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m client = OpenAI(\n\u001b[32m      4\u001b[39m     base_url=\u001b[33m'\u001b[39m\u001b[33mhttp://10.6.142.65:11434/v1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     api_key=\u001b[33m'\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# requerido, pero no se usa realmente\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m.completions.create(\n\u001b[32m      9\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama3.2:latest\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# o el nombre de tu modelo local\u001b[39;00m\n\u001b[32m     10\u001b[39m     messages=[\n\u001b[32m     11\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mEres un asistente útil.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     12\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m¿Cuál es la diferencia entre Ollama y llama.cpp?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     13\u001b[39m     ],\n\u001b[32m     14\u001b[39m     temperature=\u001b[32m0.7\u001b[39m,\n\u001b[32m     15\u001b[39m     max_tokens=\u001b[32m250\u001b[39m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices.message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.6-windows-x86_64-none\\Lib\\functools.py:993\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m    991\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    995\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\_client.py:165\u001b[39m, in \u001b[36mOpenAI.chat\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Chat:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresources\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Chat(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Chat,\n\u001b[32m     13\u001b[39m     AsyncChat,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncChatWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Audio,\n\u001b[32m     21\u001b[39m     AsyncAudio,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncAudioWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     Beta,\n\u001b[32m      5\u001b[39m     AsyncBeta,\n\u001b[32m      6\u001b[39m     BetaWithRawResponse,\n\u001b[32m      7\u001b[39m     AsyncBetaWithRawResponse,\n\u001b[32m      8\u001b[39m     BetaWithStreamingResponse,\n\u001b[32m      9\u001b[39m     AsyncBetaWithStreamingResponse,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthreads\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     Threads,\n\u001b[32m     13\u001b[39m     AsyncThreads,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     AsyncThreadsWithStreamingResponse,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massistants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     Assistants,\n\u001b[32m     21\u001b[39m     AsyncAssistants,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     AsyncAssistantsWithStreamingResponse,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\beta.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat, AsyncChat\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01massistants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     Assistants,\n\u001b[32m      9\u001b[39m     AsyncAssistants,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     AsyncAssistantsWithStreamingResponse,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_resource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyncAPIResource, AsyncAPIResource\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chat, AsyncChat\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completions, AsyncCompletions\n\u001b[32m      6\u001b[39m __all__ = [\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCompletions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncCompletions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mChat\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncChat\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\chat.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompletions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Completions, AsyncCompletions\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_resource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SyncAPIResource, AsyncAPIResource\n\u001b[32m      9\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mChat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAsyncChat\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:27\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_parsing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     ResponseFormatT,\n\u001b[32m     22\u001b[39m     validate_input_tools \u001b[38;5;28;01mas\u001b[39;00m _validate_input_tools,\n\u001b[32m     23\u001b[39m     parse_chat_completion \u001b[38;5;28;01mas\u001b[39;00m _parse_chat_completion,\n\u001b[32m     24\u001b[39m     type_to_response_format_param \u001b[38;5;28;01mas\u001b[39;00m _type_to_response_format,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatModel\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstreaming\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatCompletionStreamManager, AsyncChatCompletionStreamManager\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_params\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metadata, ReasoningEffort\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_completion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatCompletion\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\lib\\streaming\\chat\\__init__.py:21\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     ParsedChoiceSnapshot \u001b[38;5;28;01mas\u001b[39;00m ParsedChoiceSnapshot,\n\u001b[32m      3\u001b[39m     ParsedChatCompletionSnapshot \u001b[38;5;28;01mas\u001b[39;00m ParsedChatCompletionSnapshot,\n\u001b[32m      4\u001b[39m     ParsedChatCompletionMessageSnapshot \u001b[38;5;28;01mas\u001b[39;00m ParsedChatCompletionMessageSnapshot,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_events\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     ChunkEvent \u001b[38;5;28;01mas\u001b[39;00m ChunkEvent,\n\u001b[32m      8\u001b[39m     ContentDoneEvent \u001b[38;5;28;01mas\u001b[39;00m ContentDoneEvent,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     FunctionToolCallArgumentsDeltaEvent \u001b[38;5;28;01mas\u001b[39;00m FunctionToolCallArgumentsDeltaEvent,\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_completions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     ChatCompletionStream \u001b[38;5;28;01mas\u001b[39;00m ChatCompletionStream,\n\u001b[32m     23\u001b[39m     AsyncChatCompletionStream \u001b[38;5;28;01mas\u001b[39;00m AsyncChatCompletionStream,\n\u001b[32m     24\u001b[39m     ChatCompletionStreamState \u001b[38;5;28;01mas\u001b[39;00m ChatCompletionStreamState,\n\u001b[32m     25\u001b[39m     ChatCompletionStreamManager \u001b[38;5;28;01mas\u001b[39;00m ChatCompletionStreamManager,\n\u001b[32m     26\u001b[39m     AsyncChatCompletionStreamManager \u001b[38;5;28;01mas\u001b[39;00m AsyncChatCompletionStreamManager,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GitHub\\OCR_NODO_WORK\\.venv\\Lib\\site-packages\\openai\\lib\\streaming\\chat\\_completions.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Generic, Callable, Iterable, Awaitable, AsyncIterator, cast\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self, Iterator, assert_never\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjiter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_json\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParsedChoiceSnapshot, ParsedChatCompletionSnapshot, ParsedChatCompletionMessageSnapshot\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_events\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     ChunkEvent,\n\u001b[32m     13\u001b[39m     ContentDoneEvent,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     FunctionToolCallArgumentsDeltaEvent,\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'from_json' from 'jiter' (unknown location)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://10.6.142.65:11434/v1',\n",
    "    api_key='ollama'  # requerido, pero no se usa realmente\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2:latest\",  # o el nombre de tu modelo local\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente útil.\"},\n",
    "        {\"role\": \"user\", \"content\": \"¿Cuál es la diferencia entre Ollama y llama.cpp?\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=250\n",
    ")\n",
    "\n",
    "print(response.choices.message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe1771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
